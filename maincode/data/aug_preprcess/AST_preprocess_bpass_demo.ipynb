{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08f4b638-81a0-40a8-9af6-6a25f4e69851",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dave\\anaconda3\\envs\\haikoo\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import ast_preprocess_dataloader\n",
    "from ast_preprocess_dataloader import AudioPipeline\n",
    "import torchaudio\n",
    "import torch\n",
    "import os\n",
    "import glob\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from audiomentations import Compose, TimeStretch, PitchShift, HighPassFilter, LowPassFilter, BandPassFilter\n",
    "import numpy as np\n",
    "from transformers import AutoProcessor\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f2710c-5152-41f6-b75c-802ce2076174",
   "metadata": {},
   "source": [
    "## **오디오 경로 불러오기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f04c4eca-7be0-4b8a-83f7-9b8378b15727",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_path = r'C:../dataset/audioonly/labeled/orig_resample'\n",
    "os.path.exists(dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2dc0cd84-0b11-4c47-a355-380c07ccd331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bellypain', 'discomfort', 'hungry', 'tired']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_name = os.listdir(dir_path)\n",
    "class_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4d8f3ea-2fc3-48fc-baa5-e91d2064d17c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:../dataset/audioonly/labeled/orig_resample\\\\bellypain',\n",
       " 'C:../dataset/audioonly/labeled/orig_resample\\\\discomfort',\n",
       " 'C:../dataset/audioonly/labeled/orig_resample\\\\hungry',\n",
       " 'C:../dataset/audioonly/labeled/orig_resample\\\\tired']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_dir = [os.path.join(dir_path, name) for name in class_name]\n",
    "audio_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd98d13f-2790-449f-9173-63f2cac9e6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bpain_audio = glob.glob(os.path.join(audio_dir[0], '*.wav'))\n",
    "discomf_audio = glob.glob(os.path.join(audio_dir[1], '*.wav'))\n",
    "hungry_audio = glob.glob(os.path.join(audio_dir[2], '*.wav'))\n",
    "tired_audio = glob.glob(os.path.join(audio_dir[3], '*.wav'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa67272f-edc1-4fc3-8b2f-e6edb6aff47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_path_class = {\n",
    "    'bpain': bpain_audio,\n",
    "    'discomf': discomf_audio,\n",
    "    'hungry': hungry_audio,\n",
    "    'tired': tired_audio\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38691359-8501-42ab-9adf-a99136489ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_paths = []\n",
    "all_labels = []\n",
    "\n",
    "for (label, class_name), path_lst in zip(enumerate(audio_path_class), audio_path_class.values()):\n",
    "    for path in path_lst:\n",
    "        all_paths.append(path)\n",
    "        all_labels.append(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdb0657-2dab-4836-9004-bbdccb6ca035",
   "metadata": {},
   "source": [
    "## **훈련, 검증, 테스트 경로 쪼개기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6bf4d86d-8a44-4319-b859-e64813cc113b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_paths, val_paths, train_labels, val_labels = train_test_split(all_paths, all_labels, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d86723fb-ef24-45a7-a992-a893462045a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137\n",
      "60\n",
      "137\n",
      "60\n"
     ]
    }
   ],
   "source": [
    "# 갯수 확인\n",
    "print(len(train_paths))\n",
    "print(len(val_paths))\n",
    "print(len(train_labels))\n",
    "print(len(val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c858ab9e-2b47-4407-af25-7ba358e69bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_paths, test_paths, val_labels, test_labels = train_test_split(val_paths, val_labels, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78b0d471-a0cd-4968-98b2-b84b7b026e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "30\n",
      "30\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "# 갯수 확인\n",
    "print(len(val_paths))\n",
    "print(len(test_paths))\n",
    "print(len(val_labels))\n",
    "print(len(test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0336d9eb-b0ee-4351-871d-1991759ab6f5",
   "metadata": {},
   "source": [
    "## **파이프라인 만들기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9026d259-af93-41aa-bd48-e38eacf42cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration. Please open a PR/issue to update `preprocessor_config.json` to use `image_processor_type` instead of `feature_extractor_type`. This warning will be removed in v4.40.\n",
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration. Please open a PR/issue to update `preprocessor_config.json` to use `image_processor_type` instead of `feature_extractor_type`. This warning will be removed in v4.40.\n",
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration. Please open a PR/issue to update `preprocessor_config.json` to use `image_processor_type` instead of `feature_extractor_type`. This warning will be removed in v4.40.\n"
     ]
    }
   ],
   "source": [
    "augmentations = Compose([\n",
    "    BandPassFilter(min_center_freq=1500, max_center_freq=1500,\n",
    "                   max_bandwidth_fraction=0.8, min_bandwidth_fraction=0.8,\n",
    "                   max_rolloff=12, min_rolloff=12, p=1.0)\n",
    "])\n",
    "\n",
    "train_dataset = AudioPipeline(audio_paths=train_paths, audio_labels=train_labels, sr=20000, transform=augmentations)\n",
    "val_dataset = AudioPipeline(audio_paths=val_paths, audio_labels=val_labels, sr=20000)\n",
    "test_dataset = AudioPipeline(audio_paths=val_paths, audio_labels=val_labels, sr=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b4102c4-c55e-4f7e-9172-9e5efc4cd9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=10, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=10, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67fbe9c-721a-4108-95de-6494ffb30d35",
   "metadata": {},
   "source": [
    "## **훈련, 검증, 테스트 batch 불러오기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e9ce7c70-679e-4155-aa94-8669b783b707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1024, 128]) torch.Size([10])\n",
      "torch.Size([10, 1024, 128]) torch.Size([10])\n",
      "torch.Size([10, 1024, 128]) torch.Size([10])\n",
      "torch.Size([10, 1024, 128]) torch.Size([10])\n",
      "torch.Size([10, 1024, 128]) torch.Size([10])\n",
      "torch.Size([10, 1024, 128]) torch.Size([10])\n",
      "torch.Size([10, 1024, 128]) torch.Size([10])\n",
      "torch.Size([10, 1024, 128]) torch.Size([10])\n",
      "torch.Size([10, 1024, 128]) torch.Size([10])\n",
      "torch.Size([10, 1024, 128]) torch.Size([10])\n",
      "torch.Size([10, 1024, 128]) torch.Size([10])\n",
      "torch.Size([10, 1024, 128]) torch.Size([10])\n",
      "torch.Size([10, 1024, 128]) torch.Size([10])\n",
      "torch.Size([7, 1024, 128]) torch.Size([7])\n"
     ]
    }
   ],
   "source": [
    "# 훈련 데이터 배치 불러오기\n",
    "for batch in train_dataloader:\n",
    "    input_values, labels = batch\n",
    "    print(input_values.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f21bb22-ca4f-462c-a28b-d222593f96c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1024, 128]) torch.Size([10])\n",
      "torch.Size([10, 1024, 128]) torch.Size([10])\n",
      "torch.Size([10, 1024, 128]) torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "# 검증 데이터 배치 불러오기\n",
    "for batch in val_dataloader:\n",
    "    input_values, labels = batch\n",
    "    print(input_values.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3be8117c-1e28-4df1-8fb4-3e87a1777915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1024, 128]) torch.Size([10])\n",
      "torch.Size([10, 1024, 128]) torch.Size([10])\n",
      "torch.Size([10, 1024, 128]) torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터 배치 불러오기\n",
    "for batch in test_dataloader:\n",
    "    input_values, labels = batch\n",
    "    print(input_values.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58fc7228-3cd2-4498-b708-332089152547",
   "metadata": {},
   "source": [
    "## **훈련, 검증 에폭적용시**\n",
    "\n",
    "**아래와 같이 맞춰주시면 됩니다.**\n",
    "\n",
    "```python\n",
    "# 검증 데이터 배치 불러오기\n",
    "for epoch in range(10):\n",
    "    total_loss, correct, total = 0, 0, 0\n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}\")\n",
    "\n",
    "    # Training phase\n",
    "    for batch in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        input_values, labels = batch\n",
    "        input_values, labels = input_values.to(device), labels.to(device)\n",
    "\n",
    "        loss, logits = model(input_values, labels)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Calculate accuracy\n",
    "        preds = logits.argmax(dim=1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        progress_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "    train_accuracy = correct / total\n",
    "    train_losses.append(total_loss / len(train_loader))\n",
    "    train_accuracies.append(train_accuracy)\n",
    "\n",
    "    # Validation phase\n",
    "    if val_loader is not None:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss, correct, total = 0, 0, 0\n",
    "            for batch in val_dataloader:\n",
    "                input_values, labels = batch\n",
    "                input_values, labels = input_values.to(device), labels.to(device)\n",
    "\n",
    "                loss, logits = model(input_values, labels)\n",
    "                val_loss += loss.item()\n",
    "                preds = logits.argmax(dim=1)\n",
    "                correct += (preds == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "\n",
    "            val_accuracy = correct / total\n",
    "            val_losses.append(val_loss / len(val_loader))\n",
    "            val_accuracies.append(val_accuracy)\n",
    "\n",
    "        model.train()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a783c1-d366-4b39-9ff4-c1d6b51ba8c5",
   "metadata": {},
   "source": [
    "## **테스트 적용시**\n",
    "\n",
    "```python\n",
    "model.eval()  \n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():  \n",
    "    for data in test_dataloader:  \n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "haikoo",
   "language": "python",
   "name": "haikoo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
