{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/knggu/EUANGGG/blob/haikoo/maincode/data/experiment/ASTFeatureExtractor_exp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SsQ4z0gz7lcp",
        "outputId": "fe9c0f5b-fc03-4298-ece0-56c67c5ff941"
      },
      "id": "SsQ4z0gz7lcp",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "342d0d9b-e561-4ef9-a705-b37a7cea1777",
      "metadata": {
        "id": "342d0d9b-e561-4ef9-a705-b37a7cea1777"
      },
      "outputs": [],
      "source": [
        "from transformers import ASTFeatureExtractor, AutoProcessor\n",
        "import librosa\n",
        "import zipfile\n",
        "import torch\n",
        "from transformers import AutoProcessor\n",
        "import os\n",
        "import glob\n",
        "from tqdm import tqdm\n",
        "from transformers import ASTConfig, ASTModel\n",
        "import numpy as np\n",
        "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
        "from transformers import ASTForAudioClassification, Trainer, TrainingArguments"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Check if a GPU is available and set the device accordingly\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"PyTorch is using GPU 🟢\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"PyTorch is using CPU 🟡\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FsY7WtCwda6g",
        "outputId": "7f8ce024-da83-4a70-db52-de1249d73175"
      },
      "id": "FsY7WtCwda6g",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch is using GPU 🟢\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "cc2a11f2-9b9c-4e38-ab69-8d7041bdc681",
      "metadata": {
        "id": "cc2a11f2-9b9c-4e38-ab69-8d7041bdc681",
        "outputId": "cf42826d-3eb6-4723-ce41-726a8c2e3116",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "dir_path = '/content/drive/MyDrive/Colab Notebooks/euanggg/dataset/set 2.2'\n",
        "os.path.exists(dir_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "f3d8f210-98c6-4da7-a394-aca35ea49ef5",
      "metadata": {
        "id": "f3d8f210-98c6-4da7-a394-aca35ea49ef5",
        "outputId": "bea6e3f2-606b-44bf-a97e-8d26527a3a4c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['hungry', 'discomfort', 'bpain', 'tired']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "class_name = next(os.walk(dir_path))[1]\n",
        "class_name.remove('.ipynb_checkpoints')\n",
        "class_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "aac3e00d-0cfe-45d4-a4ef-21a7a8d375d1",
      "metadata": {
        "id": "aac3e00d-0cfe-45d4-a4ef-21a7a8d375d1",
        "outputId": "3864bf98-2ad4-4eac-ee11-d6a96b7729a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/Colab Notebooks/euanggg/dataset/set 2.2/hungry',\n",
              " '/content/drive/MyDrive/Colab Notebooks/euanggg/dataset/set 2.2/discomfort',\n",
              " '/content/drive/MyDrive/Colab Notebooks/euanggg/dataset/set 2.2/bpain',\n",
              " '/content/drive/MyDrive/Colab Notebooks/euanggg/dataset/set 2.2/tired']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "audio_dir = [os.path.join(dir_path, name) for name in class_name]\n",
        "audio_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "a498457a-7f97-4302-8546-2bf13ecfd379",
      "metadata": {
        "id": "a498457a-7f97-4302-8546-2bf13ecfd379"
      },
      "outputs": [],
      "source": [
        "bpain_audio = glob.glob(os.path.join(audio_dir[2], '*.wav'))\n",
        "discomf_audio = glob.glob(os.path.join(audio_dir[1], '*.wav'))\n",
        "hungry_audio = glob.glob(os.path.join(audio_dir[0], '*.wav'))\n",
        "tired_audio = glob.glob(os.path.join(audio_dir[3], '*.wav'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "4fc8b84a-6f66-4ed9-8720-c7ffb55a7d8f",
      "metadata": {
        "id": "4fc8b84a-6f66-4ed9-8720-c7ffb55a7d8f",
        "outputId": "01cfe319-0b51-4cf1-ebef-a3ac949a4985",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "len(hungry_audio)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "c0451dcf-570a-4061-9fe8-ea6c725cbc13",
      "metadata": {
        "id": "c0451dcf-570a-4061-9fe8-ea6c725cbc13"
      },
      "outputs": [],
      "source": [
        "audio_path_class = {\n",
        "    'bpain': bpain_audio,\n",
        "    'discomf': discomf_audio,\n",
        "    'hungry': hungry_audio,\n",
        "    'tired': tired_audio\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11c74a96-137f-4aa5-a57b-7c31690bf495",
      "metadata": {
        "id": "11c74a96-137f-4aa5-a57b-7c31690bf495"
      },
      "source": [
        "## **Librosa로 오디오 불러오기**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "6e59f464-5352-4674-a7b4-8499d1eba3d4",
      "metadata": {
        "id": "6e59f464-5352-4674-a7b4-8499d1eba3d4"
      },
      "outputs": [],
      "source": [
        "def convert_audio(pathdict):\n",
        "    audio_load = {}\n",
        "\n",
        "    for class_name, path in tqdm(pathdict.items()):\n",
        "        temp = []\n",
        "        for file in path:\n",
        "            audio, sr = librosa.load(file, sr = 16000)\n",
        "            temp.append(audio)\n",
        "        audio_load[class_name] = temp\n",
        "    return audio_load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "ccb58f8c-ffc9-4e79-aaa8-d7582678f750",
      "metadata": {
        "id": "ccb58f8c-ffc9-4e79-aaa8-d7582678f750",
        "outputId": "2d4abf85-1f20-41b4-b8aa-fe8f5777b900",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4/4 [00:03<00:00,  1.19it/s]\n"
          ]
        }
      ],
      "source": [
        "loaded_audio = convert_audio(audio_path_class)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "488360a3-4ebb-47b4-a493-48bd6c4fc720",
      "metadata": {
        "id": "488360a3-4ebb-47b4-a493-48bd6c4fc720"
      },
      "source": [
        "## **AutoProcessor 불러오기**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "d2be7932-d5db-42f9-9c7e-02c558175941",
      "metadata": {
        "id": "d2be7932-d5db-42f9-9c7e-02c558175941",
        "outputId": "c887efd5-c928-4419-d076-431b9bf7c656",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n"
          ]
        }
      ],
      "source": [
        "processor = AutoProcessor.from_pretrained(\"MIT/ast-finetuned-audioset-10-10-0.4593\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "e68e3ebc-83ce-4217-af15-569da7d38dbf",
      "metadata": {
        "id": "e68e3ebc-83ce-4217-af15-569da7d38dbf"
      },
      "outputs": [],
      "source": [
        "input_byclass = {}\n",
        "for class_name, audio_load in loaded_audio.items():\n",
        "    temp = []\n",
        "    for audio in audio_load:\n",
        "        input = processor(audio, sampling_rate = 16000, return_tensor = 'pt')\n",
        "        temp.append(input['input_values'])\n",
        "    input_byclass[class_name] = np.array(temp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "dba758a6-012e-4535-8768-5378dc4bb359",
      "metadata": {
        "id": "dba758a6-012e-4535-8768-5378dc4bb359"
      },
      "outputs": [],
      "source": [
        "all_data = []\n",
        "all_labels = []\n",
        "for label, class_data in enumerate(input_byclass):\n",
        "    all_data.append(input_byclass[class_data])  # Append class data\n",
        "    all_labels.append(np.full(len(input_byclass[class_data]), label))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "9b92031c-d733-4188-a09b-bcf5d560a5e8",
      "metadata": {
        "id": "9b92031c-d733-4188-a09b-bcf5d560a5e8"
      },
      "outputs": [],
      "source": [
        "all_data = np.concatenate(all_data, axis=0)\n",
        "all_labels = np.concatenate(all_labels, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "79acf320-808b-4b9c-90e5-45f0182ee2c4",
      "metadata": {
        "id": "79acf320-808b-4b9c-90e5-45f0182ee2c4"
      },
      "outputs": [],
      "source": [
        "# Convert to PyTorch tensors\n",
        "all_data_tensor = torch.tensor(all_data, dtype=torch.float32)\n",
        "all_labels_tensor = torch.tensor(all_labels, dtype=torch.long)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "47e81be1-41bc-491b-86d4-73cc8ef64d08",
      "metadata": {
        "id": "47e81be1-41bc-491b-86d4-73cc8ef64d08"
      },
      "outputs": [],
      "source": [
        "squeezed_data = all_data_tensor.squeeze(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "0c6f2b56-675f-4fff-be2b-390ee6e330a6",
      "metadata": {
        "id": "0c6f2b56-675f-4fff-be2b-390ee6e330a6",
        "outputId": "199cedf2-b382-4a02-c013-22aea227b843",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([340])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "all_labels_tensor.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "9ff254c0-7ab6-47af-b493-62295f149461",
      "metadata": {
        "id": "9ff254c0-7ab6-47af-b493-62295f149461"
      },
      "outputs": [],
      "source": [
        "dataset = TensorDataset(squeezed_data, all_labels_tensor)\n",
        "\n",
        "# Determine the size of each split\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "# Split the dataset into training and validation sets\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9af6a22-4ba7-4b9a-a21d-f6ab5ea00464",
      "metadata": {
        "id": "d9af6a22-4ba7-4b9a-a21d-f6ab5ea00464"
      },
      "source": [
        "## **모델 불러오기**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "6efd1602-965f-4946-8669-2242c606e5b3",
      "metadata": {
        "id": "6efd1602-965f-4946-8669-2242c606e5b3"
      },
      "outputs": [],
      "source": [
        "model = ASTModel.from_pretrained(\"MIT/ast-finetuned-audioset-10-10-0.4593\").to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "567ba2c8-1b6f-403c-affc-216ba227fbd9",
      "metadata": {
        "id": "567ba2c8-1b6f-403c-affc-216ba227fbd9"
      },
      "outputs": [],
      "source": [
        "for name, param in model.named_parameters():\n",
        "    param.requires_grad = False"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.config.hidden_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2RThAW1UEjUg",
        "outputId": "e9fac8b1-1f1f-4529-dab3-de03d7c60f8d"
      },
      "id": "2RThAW1UEjUg",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "768"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "243a3f51-665f-4864-afda-a5cd4b9a69b4",
      "metadata": {
        "id": "243a3f51-665f-4864-afda-a5cd4b9a69b4"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class CustomASTClassifier(nn.Module):\n",
        "    def __init__(self, ast_model_name, num_labels):\n",
        "        super().__init__()\n",
        "        self.ast = ASTModel.from_pretrained(ast_model_name)\n",
        "        # Adding a dense layer for classification\n",
        "        self.classifier = nn.Linear(self.ast.config.hidden_size, num_labels)\n",
        "        self.num_labels = num_labels  # Define num_labels as an attribute\n",
        "\n",
        "    def forward(self, input_values, labels=None):\n",
        "        outputs = self.ast(input_values)\n",
        "        embeddings = outputs.last_hidden_state\n",
        "        logits = self.classifier(embeddings.mean(dim=1))\n",
        "        # Add further logic for calculating loss if labels are provided\n",
        "        if labels is not None:\n",
        "            loss_fct = nn.CrossEntropyLoss()\n",
        "            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
        "            return loss, logits\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "0a194dc4-f920-46e8-b988-8f3327a88c63",
      "metadata": {
        "id": "0a194dc4-f920-46e8-b988-8f3327a88c63"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "num_labels = 4\n",
        "ast_model_name = \"MIT/ast-finetuned-audioset-10-10-0.4593\"\n",
        "model = CustomASTClassifier(ast_model_name, num_labels).to(device)\n",
        "\n",
        "# Define your optimizer, loss function, etc.\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(10):\n",
        "    for batch in train_loader:  # Iterates over the batches\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Unpack your data and labels from the batch\n",
        "        input_values, labels = batch  # Modify this line according to your data structure\n",
        "        input_values, labels = input_values.to(device), labels.to(device)\n",
        "\n",
        "        # Forward pass, backward pass, optimize\n",
        "        loss, logits = model(input_values, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "8feb62e7-3d2f-4de4-9c76-93adbb3d3dac",
      "metadata": {
        "id": "8feb62e7-3d2f-4de4-9c76-93adbb3d3dac",
        "outputId": "07d8fccc-df2c-4ccd-86e7-6ddadf44aa18",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([340, 1, 1024, 128])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "all_data_tensor.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "60874e91-90f1-40dc-b1da-3118ef6d13c8",
      "metadata": {
        "id": "60874e91-90f1-40dc-b1da-3118ef6d13c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebbf67be-5498-4cc6-9045-282ca89ab034"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 75.00%\n"
          ]
        }
      ],
      "source": [
        "model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():  # Disable gradient computation\n",
        "    for data in val_loader:  # dataloader is your DataLoader for the dataset\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = correct / total\n",
        "print(f'Accuracy: {accuracy * 100:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "840b17be-70ac-4d28-a1e4-9452f14e3f33",
      "metadata": {
        "id": "840b17be-70ac-4d28-a1e4-9452f14e3f33"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "be093313-de80-4de8-b98f-968e555bf3e8",
      "metadata": {
        "id": "be093313-de80-4de8-b98f-968e555bf3e8"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "haikoo",
      "language": "python",
      "name": "haikoo"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "colab": {
      "provenance": [],
      "gpuType": "V100",
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}